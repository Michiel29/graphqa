{
    "add_configs": ["../roberta/small.json", "../base.json", "../downstream/downstream_small.json"],

    "task": "gnn",
    "arch": "encoder_gnn__roberta_small",
    "gnn_layer_type": "mlp_concat",
    "gnn_layer_args": {
        "enc_dim": 256,
        "linear_dim": 256,
        "layer_sizes": [[256, 2]],
        "layer_norm": true,
        "n_gnn_layers": 1
    },
    "neg_type": "text",
    "layer_sizes": [[256, 1], [1, 1]],
    "gnn_mlp_layer_norm": true,
    "entity_dim": 256,

    "encoder_output_layer_type": "entity_start_linear",
    // "data_path": "../data/nki/bin-v5-threshold20-small",
    "data_path": "../data/nki/bin-v5-threshold20",

    "min_common_neighbors": 10,
    "max_common_neighbors": 10,
    "max_entities_size": 600,
    "max_entities_from_queue": 5,
    "total_negatives": 100,
    "max_hard_negatives": 50,
    "num_text_chunks": 4,

    "mask_type": "start_end",
    "non_mask_rate": 0,
    "subsampling_strategy": "by_entity_pair",
    "subsampling_cap": 1,
    "epoch_size": 18000,
    "n_valid_examples": 400,

    "max_epoch": 200,
    "warmup_updates": 1000,
    "total_num_updates": 10000000,
    "lr": [1e-4],

    "num_workers": 0,
    "max_sentences": 1000,
    "update_freq": [22],
    "max_tokens": 18000,
    // batch size ~ 2278.7
    "required_batch_size_multiple": 1,

    "validate_before_training": true,

    "criterion": "cross_entropy_custom"
}
