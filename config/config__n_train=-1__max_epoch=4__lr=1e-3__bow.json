{
    "task": "triplet_inference",
    "arch": "encoder_triplet__roberta_base",
    "data_path": "/data2/urikz/nki/bin-small",

    "entity_dim": 256,

    "encoder_output_layer_type": "bag_of_words",

    "max_epoch": 4,
    "warmup_updates": 3600,
    "optimizer": "adam",
    "adam_betas": "(0.9, 0.98)",
    "adam_eps": 1e-6,
    "clip_norm": 0.0,
    "lr": [1e-3],
    "lr_scheduler": "polynomial_decay",

    "weight_decay": 0.1,
    "dropout": 0.1,
    "attention_dropout": 0.1,

    "max_sentences": 2048,
    "update_freq": [1],
    "max_positions": 512,
    "max_tokens": 2e4,
    "required-batch-size-multiple": 1,
    "skip_invalid_size_inputs_valid_test": true,

    "n_train_examples": -1,
    "n_valid_examples": -1,
    "n_test_examples": -1,

    "num_workers": 0,
    "save_dir": "/data2/urikz/nki/checkpoints/test",
    "restore_file": false,
    //"pretrain_encoder_path": "../data/roberta/roberta.base/model.pt",
    "pretrain_encoder_path": "/data2/urikz/nki/checkpoints/roberta.base/model.pt",
    "ddp_backend": "no_c10d",
    "no_epoch_checkpoints": false,

    "criterion": "cross_entropy_custom"
}
