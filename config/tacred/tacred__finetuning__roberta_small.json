{
    "add_configs": ["tacred.json", "../roberta/small.json", "../base.json"],

    "eval_downstream": false,

    "seed": 0,

    "arch": "encoder_tacred__roberta_small",
    // "entity_dim": 256,
    "entity_dim": 512,
    // "entity_dim": 768,
    "mask_type": "start_end",
    "non_mask_rate": 1,
    "encoder_output_layer_type": "entity_start_linear",

    "use_pytorch_classifier": true,
    "use_sklearn_classifier": false,

    "max_epoch": 10,
    "warmup_updates": 2553, // bsz=16, max_epoch=10
    // "warmup_updates": 1277, // bsz=32, max_epoch=10
    // "warmup_updates": 638, // bsz=64, max_epoch=10
    // "warmup_updates": 322, // bsz=128, max_epoch=10
    // "warmup_updates": 161, // bsz=256, max_epoch=10
    // "lr": [5e-6],
    // "lr": [1e-5],
    "lr": [2e-5],
    // "lr": [3e-5],
    // "lr_scheduler": "fixed",
    // "weight_decay": 0.01,

    "max_sentences": 16,
    "update_freq": [1],
    // "update_freq": [2],
    // "update_freq": [4],
    // "update_freq": [8],
    // "update_freq": [16],
    "max_tokens": 2e4,

    "num_workers": 0,
    // "load_component_prefix": "encoder",

    // "restore_file": "/data1/aarchan/self_inference/save/task_tacred/arch_encoder_tacred__roberta_large/encoder_output_layer_type_entity_start_linear/entity_dim_256/lr_3e-05/max_sentences_16/update_freq_4/04m_01d_02h_42m/checkpoints/checkpoint_best.pt",

    "no_epoch_checkpoints": true

}
